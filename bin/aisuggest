#!/usr/bin/env python3
"""
aisuggest - AI-powered shell suggestion client

Reads a JSON payload from stdin, queries llama-server, and outputs
a safe suffix suggestion.
"""

import sys
import json
import os
import re
import time
from urllib.request import Request, urlopen
from urllib.error import URLError, HTTPError

# Configuration
HOST = os.environ.get("SUGGESTD_HOST", "127.0.0.1")
PORT = int(os.environ.get("SUGGESTD_PORT", "11435"))
TIMEOUT = 5.0

# Debouncing configuration
DEBOUNCE_FILE = os.path.expanduser("~/.cache/aisuggest_debounce")
DEBOUNCE_INTERVAL = 0.05

# Dangerous patterns that should not be suggested unless already in buffer
DANGEROUS_PATTERNS = [
    # Destructive file operations
    r'\brm\s+-[rf]+',
    r'\brm\s+-[fr]+',
    r'\brm\s+.*\*',
    r'\brm\s+.*~',
    r'\brm\s+.*/',
    r'\bdd\b',
    r'\bmkfs\b',
    r'\bshred\b',

    # Dangerous sudo
    r'sudo\s+rm',
    r'sudo\s+dd',

    # System control
    r'\bshutdown\b',
    r'\breboot\b',
    r'\bhalt\b',
    r'\bpoweroff\b',

    # Pipe to shell
    r'\|\s*sh\b',
    r'\|\s*bash\b',
    r'curl.*\|',
    r'wget.*\|',

    # Fork bomb
    r':\(\)',

    # Dangerous permissions
    r'chmod\s+777',
    r'chmod\s+-R\s+777',

    # Force operations
    r'git\s+push\s+.*--force',
    r'git\s+push\s+.*-f\b',
    r'git\s+clean\s+.*-[dfx]+',
    r'docker\s+rm\s+.*-f',

    # Mass deletion
    r'kubectl\s+delete',
    r'terraform\s+destroy',
]


def log_debug(msg):
    """Append to a tmp file for debugging"""
    with open("/tmp/aisuggest.log", "a") as f:
        f.write(f"{msg}\n")

def build_context_prefix(buffer):
    """Build context-aware prefix for infill completion"""
    context = ""
    
    # Add recent command history as shell comments for context
    try:
        zsh_history_path = os.path.expanduser("~/.zsh_history")
        if os.path.exists(zsh_history_path):
            with open(zsh_history_path, 'r', encoding='utf-8', errors='ignore') as f:
                # Read last 2000 lines for better recent command coverage
                lines = f.readlines()[-2000:]

            # Parse commands from zsh history format
            commands = []
            for line in lines:
                line = line.strip()
                if line and ';' in line:
                    command = line.split(';', 1)[1].strip()
                    # Filter out noise: test commands, long echo commands, etc.
                    if (command and 
                        not command.startswith('echo \'{"buffer"') and
                        not command.startswith('echo ("{buffer"') and
                        len(command) < 100):  # Skip overly long commands
                        commands.append(command)

            # Deduplicate and get most recent unique commands
            seen = set()
            unique_commands = []
            for cmd in reversed(commands):
                if cmd not in seen:
                    seen.add(cmd)
                    unique_commands.insert(0, cmd)

            # Take the most recent 10 useful commands for context
            recent = unique_commands[-100:]
            if recent:
                # Format as actual shell history to help the model
                for cmd in recent:
                    context += f"{cmd}\n"
    except (OSError, IOError):
        pass
    
    # Add the buffer to complete (on the last line)
    context += buffer
    
    return context


def call_llama_server(buffer, max_tokens=16, temperature=0.3):
    """Call llama-server infill API for code completion"""
    url = f"http://{HOST}:{PORT}/infill"

    # Build prefix with context
    prefix = build_context_prefix(buffer)
    log_debug(f"Prefix length: {len(prefix)} chars")

    payload = {
        "input_prefix": prefix,
        "input_suffix": "",
        "n_predict": max_tokens,
        "temperature": temperature,
        "top_p": 0.95,
        "top_k": 50,
        "repeat_penalty": 1.1,
        "stop": ["\n", "\r", "\n\n"],
        "stream": False,
    }

    data = json.dumps(payload).encode('utf-8')
    req = Request(url, data=data, headers={'Content-Type': 'application/json'})

    try:
        t0 = time.time()
        with urlopen(req, timeout=TIMEOUT) as response:
            result = json.loads(response.read().decode('utf-8'))
            t1 = time.time()

            raw_completion = result.get('content', '')
            log_debug(f"Raw completion: {repr(raw_completion)}")
            completion = raw_completion.strip()
            log_debug(f"Latency: {(t1-t0)*1000:.0f}ms, Completion: {repr(completion)}")

            return completion
    except (URLError, HTTPError) as e:
        log_debug(f"HTTP error: {e}")
        return None
    except Exception as e:
        log_debug(f"Unexpected error: {e}")
        return None


def contains_control_chars(text):
    """Check if text contains control characters (except space/tab)"""
    for c in text:
        code = ord(c)
        if code < 32 and c not in [' ', '\t']:
            return True
    return False


def contains_dangerous_pattern(full_command, buffer):
    """Check if full command contains dangerous patterns not in buffer"""
    for pattern in DANGEROUS_PATTERNS:
        if re.search(pattern, full_command, re.IGNORECASE):
            # Check if the dangerous pattern was already in the buffer
            if not re.search(pattern, buffer, re.IGNORECASE):
                log_debug(f"Rejected: dangerous pattern '{pattern}' not in buffer")
                return True
    return False


def normalize_suggestion(buffer, suggestion):
    """Normalize and validate the suggestion"""
    if not suggestion:
        return None

    # Remove newlines/carriage returns
    if '\n' in suggestion or '\r' in suggestion:
        log_debug("Rejected: contains newline")
        return None

    # Check for control characters
    if contains_control_chars(suggestion):
        log_debug("Rejected: contains control characters")
        return None

    # If model returned the full command, try to extract just the suffix
    if suggestion.startswith(buffer):
        suggestion = suggestion[len(buffer):]
        log_debug(f"Extracted suffix: {repr(suggestion)}")

    # Strip leading whitespace unless buffer ends with whitespace
    if buffer and not buffer[-1].isspace():
        suggestion = suggestion.lstrip()

    # Check if resulting suggestion is empty or just whitespace
    if not suggestion or not suggestion.strip():
        return None

    return suggestion


def is_safe_suggestion(buffer, suggestion):
    """Apply safety filters to the suggestion"""
    if not suggestion:
        return False

    full_command = buffer + suggestion

    # Check for dangerous patterns
    if contains_dangerous_pattern(full_command, buffer):
        return False

    # Prevent suggesting dangerous pipes if not already in buffer
    if '|' in suggestion and '|' not in buffer:
        # Check if it's piping to a shell
        if re.search(r'\|\s*(sh|bash|zsh|fish)\b', suggestion):
            log_debug("Rejected: pipe to shell not in buffer")
            return False

    # Prevent suggesting sudo if not already in buffer
    if 'sudo' in suggestion.lower() and 'sudo' not in buffer.lower():
        log_debug("Rejected: sudo not in buffer")
        return False

    return True


def check_debounce():
    """Check if enough time has passed since last request"""
    current_time = time.time()

    if os.path.exists(DEBOUNCE_FILE):
        try:
            with open(DEBOUNCE_FILE, 'r') as f:
                last_request = float(f.read().strip())
            elapsed = current_time - last_request
            if elapsed < DEBOUNCE_INTERVAL:
                log_debug(f"Debounced: {elapsed*1000:.0f}ms < {DEBOUNCE_INTERVAL*1000:.0f}ms")
                return False  # Too soon, skip
        except (IOError, ValueError, OSError):
            pass  # If file is corrupted, proceed

    # Update debounce timestamp atomically
    try:
        # Create cache dir if it doesn't exist
        os.makedirs(os.path.dirname(DEBOUNCE_FILE), exist_ok=True)

        # Write to temp file then rename (atomic)
        temp_file = f"{DEBOUNCE_FILE}.tmp.{os.getpid()}"
        with open(temp_file, 'w') as f:
            f.write(str(current_time))
        os.rename(temp_file, DEBOUNCE_FILE)
    except (IOError, OSError):
        pass  # Proceed even if write fails

    return True


def main():
    """Main entry point"""
    try:
        # Read JSON input from stdin
        input_data = json.loads(sys.stdin.read())

        # Debounce check - exit early if too soon since last request
        if not check_debounce():
            sys.exit(0)

        buffer = input_data.get('buffer', '')
        cwd = input_data.get('cwd', os.getcwd())
        max_tokens = input_data.get('max_tokens', 16)

        log_debug(f"Buffer: {repr(buffer)}, CWD: {cwd}")

        # Don't suggest for empty or very short buffers
        if len(buffer.strip()) < 2:
            log_debug("Buffer too short")
            sys.exit(0)

        # Call llama-server with infill API
        suggestion = call_llama_server(buffer, max_tokens=max_tokens)

        if not suggestion:
            log_debug("No suggestion from model")
            sys.exit(0)

        # Normalize and validate
        suggestion = normalize_suggestion(buffer, suggestion)
        if not suggestion:
            log_debug("Suggestion rejected during normalization")
            sys.exit(0)

        # Apply safety filters
        if not is_safe_suggestion(buffer, suggestion):
            log_debug("Suggestion rejected by safety filter")
            sys.exit(0)

        # Output only the suffix (no newline at the end unless explicitly requested)
        print(suggestion, end='')

    except json.JSONDecodeError as e:
        log_debug(f"Invalid JSON input: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        sys.exit(130)
    except Exception as e:
        log_debug(f"Unexpected error: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
